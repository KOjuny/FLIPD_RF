run:
  dir: ${out_dir}/hydra/${now:%Y-%m-%d}/${now:%H\:%M\:%S}
sweep:
  dir: ${out_dir}/hydra/${now:%Y-%m-%d}/${now:%H\:%M\:%S}-sweep
mode: MULTIRUN

sweeper:
  params:
    # sweep over all the different small synthetic data types
    dataset: "manifolds/small/affine_10D_2d_4d_8d_gaussian,manifolds/small/affine_10D_2d_4d_8d_laplace,manifolds/small/affine_10D_2d_4d_8d_uniform,manifolds/small/affine_10D_5d_gaussian,manifolds/small/affine_10D_5d_laplace,manifolds/small/affine_10D_5d_uniform,manifolds/small/RQNSF_10D_2d_4d_8d_uniform,manifolds/small/RQNSF_10D_5d_uniform,manifolds/small/squiggly_05_freq_10D_2d_4d_8d_uniform,manifolds/small/squiggly_10_freq_10D_2d_4d_8d_uniform,manifolds/small/squiggly_1_freq_10D_2d_4d_8d_uniform,manifolds/small/squiggly_5_freq_10D_2d_4d_8d_uniform"
    
    # increase the batch size to make LIDL faster!
    train.loader.batch_size: 1024
    train.val_loader.batch_size: 1024

    +experiment: train_lidl_tabular 
    # plot everything after every single epoch
    all_callbacks.lidl.frequency: 1 
    # set the experiment name to something meaningful on mlflow
    experiment_name: lidl_small
    # set the max epochs to 25 to be fair compared to our method
    train.trainer.max_epochs: 25

    # uncomment for testing:
    # train.trainer.fast_dev_run: true 

    # Customize progress bar to avoid having a huge log in stderr of mlflow
    +callbacks@all_callbacks.progress_bar: trainer_progress_bar
    all_callbacks.progress_bar.refresh_rate: 100

    # Set to 4096 data representatives to analyze metrics
    all_callbacks.lidl.subsample_size: 4096

    sample.num: 0 # cancel final sampling (Important!)
