# Performs a sweep over a variety of datasets and LID estimators
# (1) Stanczuk et al. (2) FlipdEstimator
# These are medium synthetic data

run:
  dir: ${out_dir}/hydra/${now:%Y-%m-%d}/${now:%H\:%M\:%S}
sweep:
  dir: ${out_dir}/hydra/${now:%Y-%m-%d}/${now:%H\:%M\:%S}-sweep
mode: MULTIRUN

sweeper:
  params:
    # sweep over all the different large synthetic data types
    dataset: "manifolds/medium/affine_100D_10d_25d_50d_gaussian,manifolds/medium/affine_100D_10d_25d_50d_uniform,manifolds/medium/affine_100D_10d_30d_90d_uniform,manifolds/medium/affine_100D_10d_uniform,manifolds/medium/affine_100D_30d_gaussian,manifolds/medium/affine_100D_30d_uniform,manifolds/medium/affine_100D_90d_gaussian,manifolds/medium/affine_100D_90d_uniform,manifolds/medium/squiggly_05_freq_100D_10d_25d_50d_uniform,manifolds/medium/squiggly_05_freq_100D_50d_uniform,manifolds/medium/squiggly_10_freq_100D_10d_25d_50d_uniform,manifolds/medium/squiggly_10_freq_100D_50d_uniform,manifolds/medium/squiggly_1_freq_100D_10d_25d_50d_uniform,manifolds/medium/squiggly_1_freq_100D_50d_uniform,manifolds/medium/squiggly_5_freq_100D_10d_25d_50d_uniform,manifolds/medium/squiggly_5_freq_100D_50d_uniform"
    
    +experiment: train_diffusion_tabular 

    # monitor fpk
    +callbacks@all_callbacks.lid1: flipd_curve
    all_callbacks.lid1.frequency: 200
    all_callbacks.lid1.subsample_size: 4096
    # set a larger chunk size for faster computation of the FLIPD which is the bottleneck here
    all_callbacks.lid1.lid_estimation_args.chunk_size: 4096 

    # monitor normal bundles
    +callbacks@all_callbacks.lid2: normal_bundle_lid_curve 
    all_callbacks.lid2.frequency: 200
    all_callbacks.lid2.subsample_size: 4096
    all_callbacks.lid2.lid_preprocessing_args.score_batch_size: 4096
    
    # monitor sample quality
    +callbacks@all_callbacks.umap: umap 
    all_callbacks.umap.frequency: 200


    train.trainer.max_epochs: 400

    # set learning rate to smaller values for more accracy
    lightning_dgm.optim_partial.lr: 1e-5

    # Customize progress bar to avoid having a huge log in stderr of mlflow
    +callbacks@all_callbacks.progress_bar: trainer_progress_bar
    all_callbacks.progress_bar.refresh_rate: 1000

    # train.trainer.fast_dev_run: true # uncomment for testing
    experiment_name: diffusion_lid_synthetic_medium
    sample.num: 0 # cancel final sampling (Important!)
