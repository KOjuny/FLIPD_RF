run:
  dir: ${out_dir}/hydra/${now:%Y-%m-%d}/${now:%H\:%M\:%S}
sweep:
  dir: ${out_dir}/hydra/${now:%Y-%m-%d}/${now:%H\:%M\:%S}-sweep
mode: MULTIRUN

sweeper:
  params:
    # sweep over all the different large synthetic data types
    dataset: "manifolds/large/affine_1000D_100d_uniform,manifolds/large/affine_1000D_900d_gaussian,manifolds/large/affine_1000D_900d_uniform,manifolds/large/affine_2000D_100d_200d_uniform,manifolds/large/affine_800D_10d_80d_200d_uniform,manifolds/large/affine_800D_200d_uniform,manifolds/large/squiggly_05_freq_2000D_200d_uniform,manifolds/large/squiggly_10_freq_2000D_200d_uniform,manifolds/large/squiggly_1_freq_2000D_200d_uniform,manifolds/large/squiggly_5_freq_2000D_200d_uniform"

    # increase the batch size to make LIDL faster!
    train.loader.batch_size: 1024
    train.val_loader.batch_size: 1024

    +experiment: train_lidl_tabular 
    # plot everything after every single epoch
    all_callbacks.lidl.frequency: 1 
    # set the experiment name to something meaningful on mlflow
    experiment_name: lidl_large
    # set the max epochs to 100 to be fair compared to our method
    train.trainer.max_epochs: 100

    # uncomment for testing:
    # train.trainer.fast_dev_run: true 

    # Customize progress bar to avoid having a huge log in stderr of mlflow
    +callbacks@all_callbacks.progress_bar: trainer_progress_bar
    all_callbacks.progress_bar.refresh_rate: 100

    # Set to 4096 data representatives to analyze metrics
    all_callbacks.lidl.subsample_size: 4096

    sample.num: 0 # cancel final sampling (Important!)
